# State machine codegen

The method of implementing the DFA state machine in rust code can be changed by
enabling or disabling the crate feature `state_machine_codegen`. This has no
behavioral differences when enabled or disabled, it only affects performance
and stack memory usage.

## Feature enabled

The state machine codegen creates an Enum variant for each state, and puts the
state bodies in the arms of a match statement. The match statement is put
inside of a loop, and state transitions are implemented by assigning to the
current state variable and then `continue`ing to the start of the loop again.

```rust,no_run,noplayground
let mut state = State::State0;
loop {
    match state {
        State::State0 => {
            match lexer.read() {
                'a' => state = State::State1,
                'b' => state = State::State2,
                _ => return Token::Error,
            }
        }
        // Etc...
    }
}
```

## Feature Disabled

The tailcall code generation creates functions for each state, and state
transitions are implemented by calling the next state's function.

```rust,no_run,noplayground
fn state0(lexer: Lexer, context: Context) -> Token {
    match lexer.read() {
        'a' => state1(lexer, context),
        'b' => state2(lexer, context),
        _ => Token::Error,
    }
}

// Etc ...
```

## Considerations

The tailcall code generation generates significantly faster code and is
therefore the default. However, until rust gets guaranteed tail calls with the
`become` keyword, it is possible to overflow the stack using it. This usually
happens when many "skip" tokens are matched in a row. This can usually be
solved by wrapping your skip pattern in a repetition, but not always. In any
case, if you don't want to worry about possible stack overflows, you can use
the `state_machine_codegen` feature.

### Performance Explanation

The reason that tailcall code generation is faster is that LLVM currently
does not optimize a switch within a loop well. The resulting machine code
usually ends up with each state having a jump back to the top of the loop where
the next state is looked up out of a jump table. In contrast, the tail call
generation which usually ends up with an unconditional jump at the end of the
state directly to the next state. The unconditional jump is a little bit better
in terms of instruction count, but the real gains are in the tail call codegen
being much nicer to the branch predictor.

### Potential Mitigations

There are a couple of things that would improve the quality of the code
generated by the state machine codegen. First, if you add the
[`-enable-dfa-jump-thread`](https://github.com/llvm/llvm-project/commit/02077da7e7a8ff76c0576bb33adb462c337013f5)
LLVM pass to rustc, you end up with very similar machine code in both code
generators (but the state machine has the added benefit of no possiblity of
stack overflows). This option can be added using a `config.toml` file
([example](https://github.com/0x2a-42/herring/blob/main/.cargo/config.toml)).
It is probably not a good idea to do this in production code, as adding new
LLVM passes to rust increases the possiblity of finding compiler bugs. There is
also the possibility of this optimization being added at the rust level. This
is being explored by [RFC 3720](https://github.com/rust-lang/rfcs/pull/3720).
If that RFC is implemented, the logos state machine codegen could use the new
`loop match` construct to obtain a similar optimization.
